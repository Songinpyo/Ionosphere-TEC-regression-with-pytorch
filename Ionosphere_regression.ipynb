{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba8a3ae4",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline\n",
    "\n",
    "from torch import nn, optim                           # torch 에서 제공하는 신경망 기술, 손실함수, 최적화를 할 수 있는 함수들을 불러온다.\n",
    "from torch.utils.data import DataLoader, Dataset      # 데이터를 모델에 사용할 수 있게 정리해주는 라이브러리.\n",
    "import torch.nn.functional as F                       # torch 내의 세부적인 기능을 불러옴.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Loss\n",
    "from sklearn.metrics import mean_squared_error        # regression 문제의 모델 성능 측정을 위해서 MSE를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b711680",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kp_inter', 'Ap_inter', 'F107_inter', 'SunSpot_inter', 'dst', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T10', 'T11', 'T12', 'T13', 'T14', 'T15', 'T16', 'C_D', 'S_D', 'C_H', 'S_H', 'tec_ex(T1)']\n"
     ]
    }
   ],
   "source": [
    "# Read Data\n",
    "train = pd.read_csv(\"C:/Users/rihot/Desktop/Deep_learning/capston_assignment/Preprocessed_data/datafile_nan.csv\")\n",
    "\n",
    "# Index column drop\n",
    "# Index 열은 Quality에 영향을 주지 않음\n",
    "train = train.drop(['xq'], axis=1)\n",
    "\n",
    "# 데이터 타입에 따라 분류\n",
    "numerical_columns = train.select_dtypes(exclude='object').columns.tolist()\n",
    "\n",
    "# StandardScaler 를 이용해서 데이터 표준화를 진행한다\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# train[numerical_columns] = StandardScaler().fit_transform(train[numerical_columns])\n",
    "\n",
    "\n",
    "# 확인을 위한 호출\n",
    "print(numerical_columns)\n",
    "# train.head(5)\n",
    "# test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ec3e81b",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m Y \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtec_ex(T1)\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues\n\u001B[0;32m      2\u001B[0m X \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, rows \u001B[38;5;129;01min\u001B[39;00m train\u001B[38;5;241m.\u001B[39miterrows():\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;66;03m# 데이터 프레임을 가로 한줄씩 출력 row\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "Y = train['tec_ex(T1)'].values\n",
    "X = []\n",
    "\n",
    "for i, rows in train.iterrows():\n",
    "    # 데이터 프레임을 가로 한줄씩 출력 row\n",
    "    X.append([ rows['Kp_inter'], rows['Ap_inter'], rows['F107_inter'], rows['SunSpot_inter'], rows['dst']\n",
    "                , rows['T1'], rows['T2'], rows['T3'], rows['T4'], rows['T5'], rows['T6'], rows['T7'], rows['T8'], rows['T9']\n",
    "                , rows['T10'], rows['T11'], rows['T12'], rows['T13'], rows['T14'], rows['T15'], rows['T16']\n",
    "                , rows['C_D'], rows['S_D'], rows['C_H'], rows['S_H']])\n",
    "\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84a5953b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Y = Y.reshape((-1,1)) # reshape(-1,1) 열 값은 지정했으니 알아서 행 지정해서 배열로 만들기\n",
    "\n",
    "# 데이터 스케일링\n",
    "# sklearn에서 제공하는 MinMaxScaler \n",
    "# (X-min(X))/(max(X)-min(X))을 계산\n",
    "scaler = MinMaxScaler() \n",
    "scaler.fit(X) \n",
    "X = scaler.transform(X)\n",
    "\n",
    "scaler.fit(Y)\n",
    "Y = scaler.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4c7e40f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# torch의 Dataset 을 상속.\n",
    "class TensorData(Dataset):\n",
    "\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.FloatTensor(x_data)\n",
    "        self.y_data = torch.FloatTensor(y_data)\n",
    "        self.len = self.y_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        return self.x_data[index], self.y_data[index] \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8ad165a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#하이퍼 파라미터 튜닝\n",
    "\n",
    "CFG = {\n",
    "    'EPOCHS':150, #에포크\n",
    "    'LEARNING_RATE':3e-4, #학습률\n",
    "    'BATCH_SIZE':16, #배치사이즈\n",
    "    'SEED':41, #시드\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f9f3dd8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 전체 데이터를 학습 데이터와 평가 데이터로 나눈다.\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "# 학습 데이터, 시험 데이터 배치 형태로 구축하기\n",
    "trainsets = TensorData(X_train, Y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainsets, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "\n",
    "valsets = TensorData(X_val, Y_val)\n",
    "valloader = torch.utils.data.DataLoader(valsets, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6910834f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(25, 64, bias=False),\n",
    "            nn.BatchNorm1d(64, eps=1e-05, momentum=0.1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(64, 128, bias=False),\n",
    "            nn.BatchNorm1d(128, eps=1e-05, momentum=0.1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(128, 256, bias=False),\n",
    "            nn.BatchNorm1d(256, eps=1e-05, momentum=0.1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer4 = nn.Linear(256, 1, bias=False)\n",
    "        \n",
    "    def forward(self, x): # 모델 연산의 순서를 정의\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "      \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a57eae1c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Regressor()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'], weight_decay=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7413de7b",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_ = [] # loss 저장할 리스트\n",
    "t_loss_ = [] # test loss 저장할 리스트\n",
    "\n",
    "def train(model, optimizer, trainloader):\n",
    "    n = len(trainloader)\n",
    "    \n",
    "    # Loss Function\n",
    "    criterion = nn.MSELoss()\n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(1, CFG[\"EPOCHS\"]+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, values = data\n",
    "            \n",
    "            optimizer.zero_grad() # 최적화 초기화\n",
    "            \n",
    "            outputs = model(inputs) # 예측값 산출\n",
    "            loss = criterion(outputs, values) # Error 계산\n",
    "            \n",
    "            loss.backward() # 역전파 진행\n",
    "            optimizer.step() # 역전파 진행 후 가중치 업데이트\n",
    "            \n",
    "            running_loss += loss.item() # Epoch 마다 평균 loss를 계산하기 위한 배치 loss\n",
    "                                        # item() 텐서로 값 받아오기\n",
    "        \n",
    "        loss_.append(running_loss/n) # MSE 계산\n",
    "        print('[%d] Train loss: %.10f' %(epoch, running_loss / len(trainloader)))\n",
    "        \n",
    "        #validation set 평가\n",
    "        model.eval() #evaluation 과정에서 사용하지 않아야 하는 layer들을 알아서 off 시키도록 하는 함수\n",
    "        test_loss = 0.0\n",
    "        \n",
    "        predictions = torch.tensor([], dtype=torch.float) # 예측값을 저장하는 텐서.\n",
    "        actual = torch.tensor([], dtype=torch.float) # 실제값을 저장하는 텐서.\n",
    "        \n",
    "        with torch.no_grad(): #파라미터 업데이트 안하기 때문에 no_grad 사용\n",
    "            for i, data in enumerate(valloader, 0):\n",
    "                inputs, values = data\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                test_loss += criterion(outputs, values)\n",
    "                \n",
    "                predictions = torch.cat((predictions, outputs), 0) # cat함수를 통해 예측값을 누적.\n",
    "                actual = torch.cat((actual, values), 0) # cat함수를 통해 실제값을 누적.\n",
    "                \n",
    "                t_loss_.append(test_loss/n)\n",
    "        \n",
    "        predictions = predictions.numpy() # 넘파이 배열로 변경.\n",
    "        actual = actual.numpy() # 넘파이 배열로 변경.\n",
    "        rmse = np.sqrt(mean_squared_error(predictions, actual)) # sklearn을 이용해 RMSE를 계산.\n",
    "        print(f'test rmse:{rmse}')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1cf6390",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Train loss: 0.0251415800\n",
      "test rmse:0.10494793206453323\n",
      "[2] Train loss: 0.0128337684\n",
      "test rmse:0.08332432806491852\n",
      "[3] Train loss: 0.0096116760\n",
      "test rmse:0.08030737191438675\n",
      "[4] Train loss: 0.0083457092\n",
      "test rmse:0.06626685708761215\n",
      "[5] Train loss: 0.0079521053\n",
      "test rmse:0.066041499376297\n",
      "[6] Train loss: 0.0066763275\n",
      "test rmse:0.05984695628285408\n",
      "[7] Train loss: 0.0062243422\n",
      "test rmse:0.058048978447914124\n",
      "[8] Train loss: 0.0059946457\n",
      "test rmse:0.05737899988889694\n",
      "[9] Train loss: 0.0060218421\n",
      "test rmse:0.06196878105401993\n",
      "[10] Train loss: 0.0056223716\n",
      "test rmse:0.051994673907756805\n",
      "[11] Train loss: 0.0055441129\n",
      "test rmse:0.05325981602072716\n",
      "[12] Train loss: 0.0051042365\n",
      "test rmse:0.0606328584253788\n",
      "[13] Train loss: 0.0051810155\n",
      "test rmse:0.062218356877565384\n",
      "[14] Train loss: 0.0050703673\n",
      "test rmse:0.05577697977423668\n",
      "[15] Train loss: 0.0046195594\n",
      "test rmse:0.053287751972675323\n",
      "[16] Train loss: 0.0045658608\n",
      "test rmse:0.05481483414769173\n",
      "[17] Train loss: 0.0043044402\n",
      "test rmse:0.0507207028567791\n",
      "[18] Train loss: 0.0044725816\n",
      "test rmse:0.05555487424135208\n",
      "[19] Train loss: 0.0042087079\n",
      "test rmse:0.0665511041879654\n",
      "[20] Train loss: 0.0042903782\n",
      "test rmse:0.051261454820632935\n",
      "[21] Train loss: 0.0040538403\n",
      "test rmse:0.06303316354751587\n",
      "[22] Train loss: 0.0039089951\n",
      "test rmse:0.045524321496486664\n",
      "[23] Train loss: 0.0039906760\n",
      "test rmse:0.050135236233472824\n",
      "[24] Train loss: 0.0041512713\n",
      "test rmse:0.04904192313551903\n",
      "[25] Train loss: 0.0035505179\n",
      "test rmse:0.052750274538993835\n",
      "[26] Train loss: 0.0035761436\n",
      "test rmse:0.04662412777543068\n",
      "[27] Train loss: 0.0037145197\n",
      "test rmse:0.04432820901274681\n",
      "[28] Train loss: 0.0038941695\n",
      "test rmse:0.051463279873132706\n",
      "[29] Train loss: 0.0035793397\n",
      "test rmse:0.043881773948669434\n",
      "[30] Train loss: 0.0036531889\n",
      "test rmse:0.04906978830695152\n",
      "[31] Train loss: 0.0036281920\n",
      "test rmse:0.049038536846637726\n",
      "[32] Train loss: 0.0036000471\n",
      "test rmse:0.042798399925231934\n",
      "[33] Train loss: 0.0033517333\n",
      "test rmse:0.04111321642994881\n",
      "[34] Train loss: 0.0033475566\n",
      "test rmse:0.04263509064912796\n",
      "[35] Train loss: 0.0035091774\n",
      "test rmse:0.04284706339240074\n",
      "[36] Train loss: 0.0032137376\n",
      "test rmse:0.049114808440208435\n",
      "[37] Train loss: 0.0028060016\n",
      "test rmse:0.04465556889772415\n",
      "[38] Train loss: 0.0029328340\n",
      "test rmse:0.04440107196569443\n",
      "[39] Train loss: 0.0030314996\n",
      "test rmse:0.04762733727693558\n",
      "[40] Train loss: 0.0028747271\n",
      "test rmse:0.052364397794008255\n",
      "[41] Train loss: 0.0029593820\n",
      "test rmse:0.04001530632376671\n",
      "[42] Train loss: 0.0032150255\n",
      "test rmse:0.041655223816633224\n",
      "[43] Train loss: 0.0026178890\n",
      "test rmse:0.04828313738107681\n",
      "[44] Train loss: 0.0026038630\n",
      "test rmse:0.0407964289188385\n",
      "[45] Train loss: 0.0027846375\n",
      "test rmse:0.042157452553510666\n",
      "[46] Train loss: 0.0023429105\n",
      "test rmse:0.044376473873853683\n",
      "[47] Train loss: 0.0025194388\n",
      "test rmse:0.050338394939899445\n",
      "[48] Train loss: 0.0029158040\n",
      "test rmse:0.04316065460443497\n",
      "[49] Train loss: 0.0028770262\n",
      "test rmse:0.05030560493469238\n",
      "[50] Train loss: 0.0029781329\n",
      "test rmse:0.04112931713461876\n",
      "[51] Train loss: 0.0026900417\n",
      "test rmse:0.045137614011764526\n",
      "[52] Train loss: 0.0026327160\n",
      "test rmse:0.04067187011241913\n",
      "[53] Train loss: 0.0025914953\n",
      "test rmse:0.03690062090754509\n",
      "[54] Train loss: 0.0027682017\n",
      "test rmse:0.041555192321538925\n",
      "[55] Train loss: 0.0023744573\n",
      "test rmse:0.041642431169748306\n",
      "[56] Train loss: 0.0024351650\n",
      "test rmse:0.04236501082777977\n",
      "[57] Train loss: 0.0026091075\n",
      "test rmse:0.04342155531048775\n",
      "[58] Train loss: 0.0022751080\n",
      "test rmse:0.038563769310712814\n",
      "[59] Train loss: 0.0023661811\n",
      "test rmse:0.03570479527115822\n",
      "[60] Train loss: 0.0022653304\n",
      "test rmse:0.03760765120387077\n",
      "[61] Train loss: 0.0024966043\n",
      "test rmse:0.0392199270427227\n",
      "[62] Train loss: 0.0024764981\n",
      "test rmse:0.03900104761123657\n",
      "[63] Train loss: 0.0023884572\n",
      "test rmse:0.0462072379887104\n",
      "[64] Train loss: 0.0021843252\n",
      "test rmse:0.0332789309322834\n",
      "[65] Train loss: 0.0021529392\n",
      "test rmse:0.05135519430041313\n",
      "[66] Train loss: 0.0024094710\n",
      "test rmse:0.03465450927615166\n",
      "[67] Train loss: 0.0020677947\n",
      "test rmse:0.040562596172094345\n",
      "[68] Train loss: 0.0020619813\n",
      "test rmse:0.03119703009724617\n",
      "[69] Train loss: 0.0022341895\n",
      "test rmse:0.04398366063833237\n",
      "[70] Train loss: 0.0024211749\n",
      "test rmse:0.038888245820999146\n",
      "[71] Train loss: 0.0023435140\n",
      "test rmse:0.0354231521487236\n",
      "[72] Train loss: 0.0020069945\n",
      "test rmse:0.052724920213222504\n",
      "[73] Train loss: 0.0017860138\n",
      "test rmse:0.045901548117399216\n",
      "[74] Train loss: 0.0019253387\n",
      "test rmse:0.03826451674103737\n",
      "[75] Train loss: 0.0017706377\n",
      "test rmse:0.03411216288805008\n",
      "[76] Train loss: 0.0019382244\n",
      "test rmse:0.046749576926231384\n",
      "[77] Train loss: 0.0021958841\n",
      "test rmse:0.038039058446884155\n",
      "[78] Train loss: 0.0019598589\n",
      "test rmse:0.03365417942404747\n",
      "[79] Train loss: 0.0022053073\n",
      "test rmse:0.03700448200106621\n",
      "[80] Train loss: 0.0024885932\n",
      "test rmse:0.040932394564151764\n",
      "[81] Train loss: 0.0019263431\n",
      "test rmse:0.03946411609649658\n",
      "[82] Train loss: 0.0017593454\n",
      "test rmse:0.043028708547353745\n",
      "[83] Train loss: 0.0020673040\n",
      "test rmse:0.029877545312047005\n",
      "[84] Train loss: 0.0018080605\n",
      "test rmse:0.046101219952106476\n",
      "[85] Train loss: 0.0016273915\n",
      "test rmse:0.03390135616064072\n",
      "[86] Train loss: 0.0019131992\n",
      "test rmse:0.03721471130847931\n",
      "[87] Train loss: 0.0015959788\n",
      "test rmse:0.034621961414813995\n",
      "[88] Train loss: 0.0017678035\n",
      "test rmse:0.03608987480401993\n",
      "[89] Train loss: 0.0016878613\n",
      "test rmse:0.03458813950419426\n",
      "[90] Train loss: 0.0015664296\n",
      "test rmse:0.03115692175924778\n",
      "[91] Train loss: 0.0019986477\n",
      "test rmse:0.03243352472782135\n",
      "[92] Train loss: 0.0016336093\n",
      "test rmse:0.03401733562350273\n",
      "[93] Train loss: 0.0021319248\n",
      "test rmse:0.038029007613658905\n",
      "[94] Train loss: 0.0015454371\n",
      "test rmse:0.038222674280405045\n",
      "[95] Train loss: 0.0022894947\n",
      "test rmse:0.040178798139095306\n",
      "[96] Train loss: 0.0017169366\n",
      "test rmse:0.027834497392177582\n",
      "[97] Train loss: 0.0013467475\n",
      "test rmse:0.029921341687440872\n",
      "[98] Train loss: 0.0016313503\n",
      "test rmse:0.03203228488564491\n",
      "[99] Train loss: 0.0016843545\n",
      "test rmse:0.04043794423341751\n",
      "[100] Train loss: 0.0017170974\n",
      "test rmse:0.03882739692926407\n",
      "[101] Train loss: 0.0014856289\n",
      "test rmse:0.030521614477038383\n",
      "[102] Train loss: 0.0018388429\n",
      "test rmse:0.030919000506401062\n",
      "[103] Train loss: 0.0018980480\n",
      "test rmse:0.03645557537674904\n",
      "[104] Train loss: 0.0016450407\n",
      "test rmse:0.030056143179535866\n",
      "[105] Train loss: 0.0014467783\n",
      "test rmse:0.02897866629064083\n",
      "[106] Train loss: 0.0017975223\n",
      "test rmse:0.03478559851646423\n",
      "[107] Train loss: 0.0016321485\n",
      "test rmse:0.025610893964767456\n",
      "[108] Train loss: 0.0013806148\n",
      "test rmse:0.03507169336080551\n",
      "[109] Train loss: 0.0016457229\n",
      "test rmse:0.034836068749427795\n",
      "[110] Train loss: 0.0016736395\n",
      "test rmse:0.02581206150352955\n",
      "[111] Train loss: 0.0016402395\n",
      "test rmse:0.03537643700838089\n",
      "[112] Train loss: 0.0015609080\n",
      "test rmse:0.03432630002498627\n",
      "[113] Train loss: 0.0015049405\n",
      "test rmse:0.02802993357181549\n",
      "[114] Train loss: 0.0016342507\n",
      "test rmse:0.02831672690808773\n",
      "[115] Train loss: 0.0011944668\n",
      "test rmse:0.038350339978933334\n",
      "[116] Train loss: 0.0014127353\n",
      "test rmse:0.025653641670942307\n",
      "[117] Train loss: 0.0012731098\n",
      "test rmse:0.025995487347245216\n",
      "[118] Train loss: 0.0013144855\n",
      "test rmse:0.02905554138123989\n",
      "[119] Train loss: 0.0013451926\n",
      "test rmse:0.03463766351342201\n",
      "[120] Train loss: 0.0012425930\n",
      "test rmse:0.030790721997618675\n",
      "[121] Train loss: 0.0016623918\n",
      "test rmse:0.026288742199540138\n",
      "[122] Train loss: 0.0013065485\n",
      "test rmse:0.0245780311524868\n",
      "[123] Train loss: 0.0012608783\n",
      "test rmse:0.024508250877261162\n",
      "[124] Train loss: 0.0012985207\n",
      "test rmse:0.02748321183025837\n",
      "[125] Train loss: 0.0011692341\n",
      "test rmse:0.035875000059604645\n",
      "[126] Train loss: 0.0016254305\n",
      "test rmse:0.04515734314918518\n",
      "[127] Train loss: 0.0014341970\n",
      "test rmse:0.03143041953444481\n",
      "[128] Train loss: 0.0011804494\n",
      "test rmse:0.02596474252641201\n",
      "[129] Train loss: 0.0010928388\n",
      "test rmse:0.026568328961730003\n",
      "[130] Train loss: 0.0016164076\n",
      "test rmse:0.030551666393876076\n",
      "[131] Train loss: 0.0016042322\n",
      "test rmse:0.02715183235704899\n",
      "[132] Train loss: 0.0013178491\n",
      "test rmse:0.02881614677608013\n",
      "[133] Train loss: 0.0011829347\n",
      "test rmse:0.02975897304713726\n",
      "[134] Train loss: 0.0016618236\n",
      "test rmse:0.034759100526571274\n",
      "[135] Train loss: 0.0013166710\n",
      "test rmse:0.028309818357229233\n",
      "[136] Train loss: 0.0013355587\n",
      "test rmse:0.02966156415641308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137] Train loss: 0.0016921572\n",
      "test rmse:0.023647816851735115\n",
      "[138] Train loss: 0.0012300747\n",
      "test rmse:0.027863213792443275\n",
      "[139] Train loss: 0.0013337734\n",
      "test rmse:0.024115461856126785\n",
      "[140] Train loss: 0.0014254584\n",
      "test rmse:0.027529748156666756\n",
      "[141] Train loss: 0.0012427645\n",
      "test rmse:0.0316234715282917\n",
      "[142] Train loss: 0.0010756306\n",
      "test rmse:0.04351009428501129\n",
      "[143] Train loss: 0.0012614746\n",
      "test rmse:0.03265957161784172\n",
      "[144] Train loss: 0.0014148929\n",
      "test rmse:0.024363605305552483\n",
      "[145] Train loss: 0.0012866402\n",
      "test rmse:0.024721411988139153\n",
      "[146] Train loss: 0.0015373118\n",
      "test rmse:0.028522111475467682\n",
      "[147] Train loss: 0.0011067335\n",
      "test rmse:0.031043745577335358\n",
      "[148] Train loss: 0.0014308463\n",
      "test rmse:0.03399321809411049\n",
      "[149] Train loss: 0.0015031109\n",
      "test rmse:0.025907224044203758\n",
      "[150] Train loss: 0.0010314290\n",
      "test rmse:0.029584970325231552\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2be23ddc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "# plt.plot(loss_,'ro',label='training loss')\n",
    "plt.plot(t_loss_,'g',label='validation loss')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10d44b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_submission['tec_ex(T1)'] = y_pred_label.astype(int)\n",
    "sample_submission.to_csv(\"C:/Users/rihot/Desktop/Deep_learning/capston_assignment/processed data/sample_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}