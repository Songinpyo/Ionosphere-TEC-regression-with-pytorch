{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba8a3ae4",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Improved_Ionosphere_regression file is modified from Ionosphere_regression.ipynb to improve the performance\n",
    "\n",
    "# Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline\n",
    "\n",
    "from torch import nn, optim                           # torch 에서 제공하는 신경망 기술, 손실함수, 최적화를 할 수 있는 함수들을 불러온다.\n",
    "from torch.utils.data import DataLoader, Dataset      # 데이터를 모델에 사용할 수 있게 정리해주는 라이브러리.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Loss\n",
    "from sklearn.metrics import mean_squared_error        # regression 문제의 모델 성능 측정을 위해서 MSE를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kp_inter', 'Ap_inter', 'F107_inter', 'SunSpot_inter', 'dst', 'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T10', 'T11', 'T12', 'T13', 'T14', 'T15', 'T16', 'C_D', 'S_D', 'C_H', 'S_H', 'tec_ex(T1)']\n"
     ]
    }
   ],
   "source": [
    "# Read Data\n",
    "dir_path = \"C:/Python/Deep_learning/Ionosphere-TEC-regression-with-pytorch/\"\n",
    "\n",
    "train = pd.read_csv( dir_path + \"Preprocessed_data/datafile_nan.csv\")\n",
    "\n",
    "# Index column drop\n",
    "# Index 열은 Quality에 영향을 주지 않음\n",
    "train = train.drop(['xq'], axis=1)\n",
    "\n",
    "# 데이터 타입에 따라 분류\n",
    "numerical_columns = train.select_dtypes(exclude='object').columns.tolist()\n",
    "\n",
    "# 확인을 위한 호출\n",
    "print(numerical_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "Y = train['tec_ex(T1)'].values\n",
    "X = []\n",
    "\n",
    "for i, rows in train.iterrows():\n",
    "    # 데이터 프레임을 가로 한줄씩 출력 row\n",
    "    X.append([ rows['Kp_inter'], rows['Ap_inter'], rows['F107_inter'], rows['SunSpot_inter']\n",
    "                , rows['T1'], rows['T2'], rows['T3'], rows['T4'], rows['T5'], rows['T6'], rows['T7'], rows['T8'], rows['T9']\n",
    "                , rows['T10'], rows['T11'], rows['T12'], rows['T13'], rows['T14'], rows['T15'], rows['T16']\n",
    "                , rows['C_D'], rows['S_D'], rows['C_H'], rows['S_H']])\n",
    "\n",
    "    # remove 'dst' column, because it has low correlation with 'tec_ex(T1)'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "Y = Y.reshape((-1,1)) # reshape(-1,1) 열 값은 지정했으니 알아서 행 지정해서 배열로 만들기\n",
    "\n",
    "# 데이터 스케일링\n",
    "# sklearn에서 제공하는 MinMaxScaler \n",
    "# (X-min(X))/(max(X)-min(X))을 계산\n",
    "scalerX = MinMaxScaler()\n",
    "scalerX.fit(X)\n",
    "X = scalerX.transform(X)\n",
    "\n",
    "scalerY = MinMaxScaler()\n",
    "scalerY.fit(Y)\n",
    "Y = scalerY.transform(Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Hyper parameter tuning\n",
    "\n",
    "CFG = {\n",
    "    'EPOCHS':20, #에포크\n",
    "    'LEARNING_RATE':3e-4, #학습률\n",
    "    'BATCH_SIZE':16, #배치사이즈\n",
    "    'SEED':41, #시드\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# torch의 Dataset 을 상속.\n",
    "class TensorData(Dataset):\n",
    "\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.FloatTensor(x_data)\n",
    "        self.y_data = torch.FloatTensor(y_data)\n",
    "        self.len = self.y_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 전체 데이터를 학습 데이터와 평가 데이터로 나눈다.\n",
    "X_train, X_T, Y_train, Y_T = train_test_split(X, Y, test_size=0.4)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_T, Y_T, test_size=0.5)\n",
    "# train : val : test = 0.6 : 0.2 : 0.2\n",
    "\n",
    "# 학습 데이터, 시험 데이터 배치 형태로 구축하기\n",
    "trainsets = TensorData(X_train, Y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainsets, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "\n",
    "valsets = TensorData(X_val, Y_val)\n",
    "valloader = torch.utils.data.DataLoader(valsets, batch_size=CFG['BATCH_SIZE'], shuffle=False)\n",
    "\n",
    "testsets = TensorData(X_test, Y_test)\n",
    "testloader = torch.utils.data.DataLoader(testsets, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(25, 64, bias=False),\n",
    "            nn.BatchNorm1d(64, eps=1e-05, momentum=0.1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(64, 128, bias=False),\n",
    "            nn.BatchNorm1d(128, eps=1e-05, momentum=0.1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(128, 256, bias=False),\n",
    "            nn.BatchNorm1d(256, eps=1e-05, momentum=0.1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer4 = nn.Linear(256, 1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "      \n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Regressor()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'], weight_decay=1e-7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_ = [] # loss 저장할 리스트\n",
    "rmse_ = [] # val rmse 저장할 리스트\n",
    "\n",
    "def train(model, optimizer, trainloader, valloader):\n",
    "    n = len(trainloader)\n",
    "\n",
    "    # Loss Function\n",
    "    criterion = nn.MSELoss()\n",
    "    best_acc = 0\n",
    "\n",
    "    for epoch in range(1, CFG[\"EPOCHS\"]+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, values = data\n",
    "\n",
    "            optimizer.zero_grad() # 최적화 초기화\n",
    "\n",
    "            outputs = model(inputs) # 예측값 산출\n",
    "            loss = criterion(outputs, values) # Error 계산\n",
    "\n",
    "            loss.backward() # 역전파 진행\n",
    "            optimizer.step() # 역전파 진행 후 가중치 업데이트\n",
    "\n",
    "            running_loss += loss.item() # Epoch 마다 평균 loss를 계산하기 위한 배치 loss\n",
    "                                        # item() 텐서로 값 받아오기\n",
    "\n",
    "        loss_.append(running_loss/n) # MSE 계산\n",
    "\n",
    "        # print('[%d] Train loss: %.10f' %(epoch, running_loss / len(trainloader)))\n",
    "\n",
    "        #validation set 평가\n",
    "\n",
    "        model.eval() #evaluation 과정에서 사용하지 않아야 하는 layer들을 알아서 off 시키도록 하는 함수\n",
    "        val_loss = 0.0\n",
    "\n",
    "        predictions = torch.tensor([], dtype=torch.float) # 예측값을 저장하는 텐서.\n",
    "        actual = torch.tensor([], dtype=torch.float) # 실제값을 저장하는 텐서.\n",
    "\n",
    "        with torch.no_grad(): #파라미터 업데이트 안하기 때문에 no_grad 사용\n",
    "            for i, data in enumerate(valloader, 0): # enumerate(인자, index)\n",
    "                inputs, values = data\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                predictions = torch.cat((predictions, outputs), 0) # cat함수를 통해 예측값을 누적.\n",
    "                actual = torch.cat((actual, values), 0) # cat함수를 통해 실제값을 누적.\n",
    "\n",
    "                # if i == len(valloader)-1:\n",
    "                #     torch.save(model.state_dict(), dir_path + \"last_model.pth\")\n",
    "\n",
    "        predictions = predictions.numpy() # 넘파이 배열로 변경.\n",
    "        actual = actual.numpy() # 넘파이 배열로 변경.\n",
    "        rmse = np.sqrt(mean_squared_error(predictions, actual)) # sklearn을 이용해 RMSE를 계산.\n",
    "        rmse_.append(rmse)\n",
    "\n",
    "        # print(f'val rmse:{rmse}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# split 개수, shuffle, seed 설정\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=41)\n",
    "n_iter = 0\n",
    "\n",
    "# for train_index, test_index in str_kf.split(X, Y):\n",
    "# 이거는 Lable도 동일한 비율로 나눌 수 있어서 좋음\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "\n",
    "    train(model, optimizer, trainloader, valloader)\n",
    "\n",
    "    n_iter += 1\n",
    "    torch.save(model.state_dict(), dir_path + str(n_iter) +\"last_model.pth\")\n",
    "    print('{} 번째, 학습데이터 크기 : {}, 검증데이터 크기 : {}'.format(n_iter, X_train.shape[0], X_val.shape[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "# plt.plot(loss_,'ro',label='training loss')\n",
    "plt.plot(rmse_,'g',label='validation loss')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test set 평가\n",
    "\n",
    "def predict(model, testloader):\n",
    "    model.eval()  #evaluation 과정에서 사용하지 않아야 하는 layer들을 알아서 off 시키도록 하는 함수\n",
    "    model_pred = []\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():  #파라미터 업데이트 안하기 때문에 no_grad 사용\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            inputs, values = data\n",
    "            outputs = model(inputs)\n",
    "            test_loss += criterion(outputs, values)\n",
    "\n",
    "            model_pred.extend(outputs.tolist())\n",
    "        print(f'test loss:{test_loss}')\n",
    "    return model_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load last model\n",
    "\n",
    "for i in range(5):\n",
    "    checkpoint = torch.load(dir_path + str(i+1) + \"last_model.pth\")\n",
    "    model = Regressor()\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "\n",
    "    if i == 0:\n",
    "        preds1 = predict(model, testloader)\n",
    "        preds1 = scalerY.inverse_transform(preds1)\n",
    "    if i == 1:\n",
    "        preds2 = predict(model, testloader)\n",
    "        preds2 = scalerY.inverse_transform(preds2)\n",
    "    if i == 2:\n",
    "        preds3 = predict(model, testloader)\n",
    "        preds3 = scalerY.inverse_transform(preds3)\n",
    "    if i == 3:\n",
    "        preds4 = predict(model, testloader)\n",
    "        preds4 = scalerY.inverse_transform(preds4)\n",
    "    if i == 4:\n",
    "        preds5 = predict(model, testloader)\n",
    "        preds5 = scalerY.inverse_transform(preds5)\n",
    "\n",
    "pred = (preds1 + preds2 + preds3 + preds4 + preds5)/5\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_test_rescale = scalerY.inverse_transform(Y_test)\n",
    "\n",
    "pred[5:10], Y_test_rescale[5:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission = pd.read_csv( dir_path + \"sample_submission.csv\")\n",
    "submission['tec_ex(T1)'] = pred\n",
    "\n",
    "submission.to_csv( dir_path + \"submit.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}